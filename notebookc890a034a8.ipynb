{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9386223,"sourceType":"datasetVersion","datasetId":5694981},{"sourceId":9386343,"sourceType":"datasetVersion","datasetId":5695087}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nfrom transformers import pipeline\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport torch\nfrom tqdm import tqdm\n\n# Check if CUDA is available and set the device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\n# Initialize models (do this only once)\nimage_to_text = pipeline(\"image-to-text\", model=\"microsoft/git-base-textcaps\", device=device)\nner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", device=device)\n\ndef load_dataset(file_path):\n    return pd.read_csv(file_path)\n\ndef download_image(url):\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        return Image.open(BytesIO(response.content))\n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading image from {url}: {str(e)}\")\n        return None\n\ndef extract_text_and_entity(image, entity_name):\n    if image is None:\n        return None\n    \n    # Get the caption (extracted text) from the image\n    result = image_to_text(image)\n    extracted_text = result[0]['generated_text']\n    \n    # Extract entities\n    entities = ner(extracted_text)\n    \n    # Extract relevant entities (quantities, measurements, etc.)\n    relevant_entities = [entity for entity in entities if entity['entity'] in ['QUANTITY', 'CARDINAL', 'PERCENT']]\n    \n    # Simple heuristic: find the entity closest to the mention of the target attribute\n    target_value = None\n    min_distance = float('inf')\n    \n    for entity in relevant_entities:\n        distance = abs(extracted_text.lower().find(entity_name.lower()) - extracted_text.lower().find(entity['word'].lower()))\n        if distance < min_distance:\n            min_distance = distance\n            target_value = entity['word']\n    \n    return target_value\n\ndef process_image(row):\n    try:\n        img = download_image(row['image_link'])\n        entity_value = extract_text_and_entity(img, row['entity_name'])\n        return entity_value\n    except Exception as e:\n        print(f\"Error processing {row['image_link']}: {str(e)}\")\n        return None\n\ndef process_batch(batch):\n    return [process_image(row) for _, row in batch.iterrows()]\n\ndef main(file_path, batch_size=16, max_workers=4):\n    df = load_dataset(file_path)\n    \n    results = []\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = []\n        for i in range(0, len(df), batch_size):\n            batch = df.iloc[i:i+batch_size]\n            futures.append(executor.submit(process_batch, batch))\n        \n        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing batches\"):\n            results.extend(future.result())\n    \n    df['extracted_value'] = results\n    return df\n\n# Example usage\nfile_path = '/kaggle/input/sagnik-sarangi2/sample.csv'  # Update this to the actual path of your CSV file\nresult_df = main(file_path)\nprint(result_df[['image_link', 'entity_name', 'entity_value', 'extracted_value']])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-13T17:10:06.996516Z","iopub.execute_input":"2024-09-13T17:10:06.997405Z","iopub.status.idle":"2024-09-13T17:14:17.162526Z","shell.execute_reply.started":"2024-09-13T17:10:06.997354Z","shell.execute_reply":"2024-09-13T17:14:17.160033Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nProcessing batches:   0%|          | 0/13 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nProcessing batches: 100%|██████████| 13/13 [04:06<00:00, 18.94s/it]","output_type":"stream"},{"name":"stdout","text":"                                            image_link  \\\n0    https://m.media-amazon.com/images/I/61I9XdN6OF...   \n1    https://m.media-amazon.com/images/I/71gSRbyXmo...   \n2    https://m.media-amazon.com/images/I/61BZ4zrjZX...   \n3    https://m.media-amazon.com/images/I/612mrlqiI4...   \n4    https://m.media-amazon.com/images/I/617Tl40LOX...   \n..                                                 ...   \n194  https://m.media-amazon.com/images/I/718M5ODio0...   \n195  https://m.media-amazon.com/images/I/61lpwH0qHb...   \n196  https://m.media-amazon.com/images/I/712sZRVe98...   \n197  https://m.media-amazon.com/images/I/71d+dz7ogk...   \n198  https://m.media-amazon.com/images/I/51WSQa1ygM...   \n\n                       entity_name    entity_value extracted_value  \n0                      item_weight      500.0 gram            None  \n1                      item_volume         1.0 cup            None  \n2                      item_weight      0.709 gram            None  \n3                      item_weight      0.709 gram            None  \n4                      item_weight  1400 milligram            None  \n..                             ...             ...             ...  \n194                    item_weight        3.0 gram            None  \n195                    item_weight        3.0 gram            None  \n196                    item_weight         2.0 ton            None  \n197  maximum_weight_recommendation     15 kilogram            None  \n198                    item_weight       14.8 gram            None  \n\n[199 rows x 4 columns]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}